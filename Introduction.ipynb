{
 "metadata": {
  "name": "",
  "signature": "sha256:9aca31520bb6e56e66c37e5f7ed430eaefbbaba32a9fec0239086f8b69299cc7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np, string\n",
      "# from bayes import probability as pr, variable, generator # one day!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class variable(object):\n",
      "    \n",
      "    '''Random variables: they have names, values, and can be histogrammed.'''\n",
      "    \n",
      "    def __init__(self,names):\n",
      "        self.names = np.atleast_1d(names)\n",
      "        self.Ndim = len(self.names)\n",
      "        self.values = np.zeros(self.Ndim,)\n",
      "        return\n",
      "    \n",
      "    def __str__(self):\n",
      "        return string.join(self.names,',')\n",
      "    \n",
      "    def histogram(self):\n",
      "        print \"Histograms coming soon!\"\n",
      "        return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class probability(object):\n",
      "    \n",
      "    '''Conditional probability distribution, Pr(A|B). \n",
      "       The value of this PDF at a particular A is a \"probability density.\"\n",
      "       Evaluating the density as a function of B gives the \"likelihood\".'''\n",
      "\n",
      "    def __init__(self,of=None,given=None,assumptions=None):\n",
      "\n",
      "        # We must have defined our dependent and independent variables,\n",
      "        # and one cannot do inference without making assumptions:\n",
      "        assert assumptions is not None\n",
      "        assert of is not None\n",
      "        assert given is not None\n",
      "        \n",
      "        self.assumptions = assumptions  # stored as a dictionary\n",
      "        self.A = of                     # a list of variables\n",
      "        self.B = given                  # another list of variables\n",
      "        \n",
      "        return\n",
      "    \n",
      "    def __str__(self):\n",
      "        return \"$Pr({A}|{B})$\".format(A=str(self.A), B=str(self.B))\n",
      "        \n",
      "    def draw(self,N):\n",
      "        '''Draw N sample values of A, given B and our assumptions.'''\n",
      "        self.samples = generator(N,self.assumptions,self.B)\n",
      "        return\n",
      "    \n",
      "#    def density(self):\n",
      "#        return density(self.A,self.B,assumptions)\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generator(N,model,parameters):\n",
      "    print \"Sampling coming soon!\"\n",
      "    return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# An Introduction to Bayesian Inference"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"Let's take some data.\" What does this sentence mean? It (usually) means we are going to acquire an array of numbers, that we assume contain some information about the thing we are trying to measure. These numbers are values of a particular \"variable\". Examples of variables include: galaxy magnitudes in a catalog, the pixel values of an image, estimates of my height, and so on."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = variable('m')\n",
      "data.values = 24.52"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We call these things \"variables\" because we realize that they *do not represent truth*. The SDSS catalog might tell you that the magnitude of a particular galaxy is m = 24.52, but that doesn't mean that you should believe it! The \"true\" magnitude of that galaxy is *uncertain*: we don't know what it is, exactly. \n",
      "\n",
      "How do we cope with this uncertainty?\n",
      "\n",
      "The answer offered by Bayesian statistics is that we must quantify our degree of belief using *probability distributions* or, for continuous variables, probability density functions (PDFs). In the example above we would suppose that the value m = 24.52 is a *sample* that has been drawn from a PDF for the variable m, and that this PDF somehow captures the difference between this value of m that we have been given (and every other value of m that we could have been given), and the \"true\" magnitude of the galaxy, mu.\n",
      "\n",
      "In order to infer mu, we'll have to *assume* a particular functional form for this probability distribution, and that PDF will always depend on some *parameters*. In the simplest case, there will be two parameters involved. The first one will be mu, the \"true\" magnitude that we are trying to infer. The other will quantify our uncertainty about mu, given our assumed PDF let's call it \"sigma\", and make it be the width parameter of a Gaussian distribution."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters = variable(['mu','sigma'])\n",
      "I = {'functional_form':'Gaussian'}\n",
      "pdf = probability(of=data,given=parameters,assumptions=I)\n",
      "print pdf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "$Pr(m|mu,sigma)$\n"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, let's imagine for a moment that we are lucky enough to be given not one SDSS catalog, but 6 -which might correspond to the case where each catalog corresponds to a separate, independent set of measurements, perhaps taken on different nights (but with an otherwise identical telescope). Under these circumstances it makes sense to imagine that our 6 resulting values of m really were drawn from our assumed *sampling distribution*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.values = [24.52,24.56,24.43,24.62,24.59,24.61]\n",
      "# data.visualize()\n",
      "data.histogram()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Histograms coming soon!\n"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check model by drawing more data... etc..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pdf.draw(100)\n",
      "data.values = pdf.samples\n",
      "# data.visualize()\n",
      "data.histogram()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sampling coming soon!\n",
        "Histograms coming soon!\n"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# prior = probability(of=pars)\n",
      "# print prior"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Why do I keep writing \"truth\", in quotes? It's to remind us that actually what we are doing is inferring the parameters of a *model*, that we are temporarily assuming to be true in order to be able to quantify uncertainty. It seems that we cannot actually know the truth: all we can do is make models that represent reality and predict the data, and then study them. *Everything we know about everything in the universe is in the form of a model,* and all of that knowledge is, to varying degrees, uncertain. *Science is about belief, not truth.* In the Bayesian picture, knowledge is *subjective*, which make sense: we are part of the universe, after all! "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}